{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nir6760/DIP_DeepKSVD/blob/main/DeepKSVD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XojEhREXeBuO"
      },
      "source": [
        "Blocks for extracting images from zip folder after uploading to colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SfB1n4cWpt66",
        "outputId": "a86158ba-5dc9-4270-d369-92f61ab54f94"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHpADc7YsTdx",
        "outputId": "e606263c-be54-4f9d-edee-3464de3f4993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/gray.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFMVFmzBdbTs"
      },
      "source": [
        "# **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPisXYoGwNwv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import time\n",
        "import Deep_KSVD_NirOren\n",
        "from scipy import linalg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRHSFf3qwTPL"
      },
      "outputs": [],
      "source": [
        "# List of the test image names BSD68:\n",
        "file_test = open(\"test_gray.txt\", \"r\")\n",
        "onlyfiles_test = []\n",
        "for e in file_test:\n",
        "    onlyfiles_test.append(e[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqPffq3UwaNk"
      },
      "outputs": [],
      "source": [
        "# List of the train image names:\n",
        "file_train = open(\"train_gray.txt\", \"r\")\n",
        "onlyfiles_train = []\n",
        "for e in file_train:\n",
        "    onlyfiles_train.append(e[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa45aAbhwc7W"
      },
      "outputs": [],
      "source": [
        "# Rescaling in [-1, 1]:\n",
        "mean = 255 / 2\n",
        "std = 255 / 2\n",
        "data_transform = transforms.Compose(\n",
        "    [Deep_KSVD.Normalize(mean=mean, std=std), Deep_KSVD.ToTensor()]\n",
        ")\n",
        "# Noise level:\n",
        "sigma = 25\n",
        "# Sub Image Size:\n",
        "sub_image_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tve4Oc4ZwmME"
      },
      "outputs": [],
      "source": [
        "# Training Dataset:\n",
        "my_Data_train = Deep_KSVD.SubImagesDataset(\n",
        "    root_dir=\"gray\",\n",
        "    image_names=onlyfiles_train,\n",
        "    sub_image_size=sub_image_size,\n",
        "    sigma=sigma,\n",
        "    transform=data_transform,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Hx_mtIfwyTS"
      },
      "outputs": [],
      "source": [
        "# Training Dataset:\n",
        "my_Data_train = Deep_KSVD.SubImagesDataset(\n",
        "    root_dir=\"gray\",\n",
        "    image_names=onlyfiles_train,\n",
        "    sub_image_size=sub_image_size,\n",
        "    sigma=sigma,\n",
        "    transform=data_transform,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGA5V_DSw2kL"
      },
      "outputs": [],
      "source": [
        "# Test Dataset:\n",
        "my_Data_test = Deep_KSVD.FullImagesDataset(\n",
        "    root_dir=\"gray\", image_names=onlyfiles_test, sigma=sigma, transform=data_transform\n",
        ")\n",
        "\n",
        "# Dataloader of the test set:\n",
        "num_images_test = 5\n",
        "indices_test = np.random.randint(0, 68, num_images_test).tolist()\n",
        "my_Data_test_sub = torch.utils.data.Subset(my_Data_test, indices_test)\n",
        "dataloader_test = DataLoader(\n",
        "    my_Data_test_sub, batch_size=1, shuffle=False, num_workers=0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymccTvvBxBZH"
      },
      "outputs": [],
      "source": [
        "# Dataloader of the training set:\n",
        "batch_size = 1\n",
        "dataloader_train = DataLoader(\n",
        "    my_Data_train, batch_size=batch_size, shuffle=True, num_workers=0\n",
        ")\n",
        "\n",
        "# Create a file to see the output during the training:\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "file_to_print = open(\"results_training.csv\", \"w\")\n",
        "file_to_print.write(str(device) + \"\\n\")\n",
        "file_to_print.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RS94CscxHcD"
      },
      "outputs": [],
      "source": [
        "# Initialization:\n",
        "patch_size = 8\n",
        "m = 16\n",
        "Dict_init = Deep_KSVD.init_dct(patch_size, m)\n",
        "Dict_init = Dict_init.to(device)\n",
        "\n",
        "c_init = (linalg.norm(Dict_init.cpu(), ord=2)) ** 2\n",
        "c_init = torch.FloatTensor((c_init,))\n",
        "c_init = c_init.to(device)\n",
        "\n",
        "w_init = torch.normal(mean=1, std=1 / 10 * torch.ones(patch_size ** 2)).float()\n",
        "w_init = w_init.to(device)\n",
        "\n",
        "D_in, H_1, H_2, H_3, H_4, D_out_lam, T, min_v, max_v = patch_size ** 2, 128, 64, 32, 16, 1, 5, -1, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9h2wHM5xj2g",
        "outputId": "375fa57e-e687-41ce-bef0-65821afcf1fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DenoisingNet_MLP(\n",
              "  (unfold): Unfold(kernel_size=(8, 8), dilation=1, padding=0, stride=1)\n",
              "  (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (linear4): Linear(in_features=32, out_features=16, bias=True)\n",
              "  (linear5): Linear(in_features=16, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Deep_KSVD.DenoisingNet_MLP(\n",
        "    patch_size,\n",
        "    D_in,\n",
        "    H_1,\n",
        "    H_2,\n",
        "    H_3,\n",
        "    H_4,\n",
        "    D_out_lam,\n",
        "    T,\n",
        "    min_v,\n",
        "    max_v,\n",
        "    Dict_init,\n",
        "    c_init,\n",
        "    w_init,\n",
        "    device,\n",
        ")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K7VTLnGx8hq"
      },
      "outputs": [],
      "source": [
        "# Construct our loss function and an Optimizer:\n",
        "criterion = torch.nn.MSELoss(reduction=\"mean\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1QhSIfwxpo4",
        "outputId": "6a29b7f5-e967-4745-8d60-79c448366ebf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start = time.time()\n",
        "epochs = 3\n",
        "running_loss = 0.0\n",
        "print_every = 1\n",
        "train_losses, test_losses = [], []\n",
        "\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "    for i, (sub_images, sub_images_noise) in enumerate(dataloader_train, 0):\n",
        "        # get the inputs\n",
        "        sub_images, sub_images_noise = (\n",
        "            sub_images.to(device),\n",
        "            sub_images_noise.to(device),\n",
        "        )\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(sub_images_noise)\n",
        "        loss = criterion(outputs, sub_images)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % print_every == print_every - 1:  # print every x mini-batches\n",
        "            train_losses.append(running_loss / print_every)\n",
        "\n",
        "            end = time.time()\n",
        "            time_curr = end - start\n",
        "            file_to_print.write(\"time:\" + \" \" + str(time_curr) + \"\\n\")\n",
        "            start = time.time()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                test_loss = 0\n",
        "\n",
        "                for patches_t, patches_noise_t in dataloader_test:\n",
        "                    patches, patches_noise = (\n",
        "                        patches_t.to(device),\n",
        "                        patches_noise_t.to(device),\n",
        "                    )\n",
        "                    outputs = model(patches_noise)\n",
        "                    loss = criterion(outputs, patches)\n",
        "                    test_loss += loss.item()\n",
        "\n",
        "                test_loss = test_loss / len(dataloader_test)\n",
        "\n",
        "            end = time.time()\n",
        "            time_curr = end - start\n",
        "            file_to_print.write(\"time:\" + \" \" + str(time_curr) + \"\\n\")\n",
        "            start = time.time()\n",
        "\n",
        "            # break if the loss is closer to the minimum loss at the paper results\n",
        "            if test_loss < 0.0085:\n",
        "                break\n",
        "\n",
        "            test_losses.append(test_loss)\n",
        "            s = \"[%d, %d] loss_train: %f, loss_test: %f\" % (\n",
        "                epoch + 1,\n",
        "                (i + 1) * batch_size,\n",
        "                running_loss / print_every,\n",
        "                test_loss,\n",
        "            )\n",
        "            s = s + \"\\n\"\n",
        "            file_to_print.write(s)\n",
        "            file_to_print.flush()\n",
        "            running_loss = 0.0\n",
        "\n",
        "        if i % (10 * print_every) == (10 * print_every) - 1:\n",
        "            torch.save(model.state_dict(), \"model.pth\")\n",
        "            np.savez(\n",
        "                \"losses.npz\", train=np.array(test_losses), test=np.array(train_losses)\n",
        "            )\n",
        "\n",
        "\n",
        "file_to_print.write(\"Finished Training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74TfBNHGdl3D"
      },
      "source": [
        "# **Model loading and Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3GmD77vubBN0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import linalg\n",
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import Deep_KSVD_NirOren\n",
        "\n",
        "from matplotlib.pyplot import imsave\n",
        "from matplotlib.pyplot import cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4tGg9UN0bikX"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejUnabC_dtyM",
        "outputId": "5ce0029f-cfe7-4784-a566-561894fd6e31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DenoisingNet_MLP(\n",
              "  (unfold): Unfold(kernel_size=(8, 8), dilation=1, padding=0, stride=1)\n",
              "  (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (linear4): Linear(in_features=32, out_features=16, bias=True)\n",
              "  (linear5): Linear(in_features=16, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Overcomplete Discrete Cosinus Transform:\n",
        "patch_size = 8\n",
        "m = 16\n",
        "Dict_init = Deep_KSVD.init_dct(patch_size, m)\n",
        "Dict_init = Dict_init.to(device)\n",
        "\n",
        "# Squared Spectral norm:\n",
        "c_init = linalg.norm(Dict_init, ord=2) ** 2\n",
        "c_init = torch.FloatTensor((c_init,))\n",
        "c_init = c_init.to(device)\n",
        "\n",
        "# Average weight:\n",
        "w_init = torch.normal(mean=1, std=1 / 10 * torch.ones(patch_size ** 2)).float()\n",
        "w_init = w_init.to(device)\n",
        "\n",
        "# Deep-KSVD:\n",
        "D_in, H_1, H_2, H_3,H_4, D_out_lam, T, min_v, max_v = patch_size ** 2, 128, 64, 32,16, 1, 7, -1, 1\n",
        "model = Deep_KSVD.DenoisingNet_MLP(\n",
        "    patch_size,\n",
        "    D_in,\n",
        "    H_1,\n",
        "    H_2,\n",
        "    H_3,\n",
        "    H_4,\n",
        "    D_out_lam,\n",
        "    T,\n",
        "    min_v,\n",
        "    max_v,\n",
        "    Dict_init,\n",
        "    c_init,\n",
        "    w_init,\n",
        "    device,\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"model.pth\", map_location=\"cpu\"))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KaZ-L17qd3-Z"
      },
      "outputs": [],
      "source": [
        "# Test image names:\n",
        "file_test = open(\"test_gray.txt\", \"r\")\n",
        "onlyfiles_test = []\n",
        "for e in file_test:\n",
        "    onlyfiles_test.append(e[:-1])\n",
        "\n",
        "# Rescaling in [-1, 1]:\n",
        "mean = 255 / 2\n",
        "std = 255 / 2\n",
        "data_transform = transforms.Compose(\n",
        "    [Deep_KSVD.Normalize(mean=mean, std=std), Deep_KSVD.ToTensor()]\n",
        ")\n",
        "# Noise level:\n",
        "sigma = 25\n",
        "\n",
        "# Test Dataset:\n",
        "my_Data_test = Deep_KSVD.FullImagesDataset(\n",
        "    root_dir=\"gray\", image_names=onlyfiles_test, sigma=sigma, transform=data_transform\n",
        ")\n",
        "\n",
        "dataloader_test = DataLoader(my_Data_test, batch_size=1, shuffle=False, num_workers=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "8CoivEpId-C_",
        "outputId": "169f9931-b148-486c-b7fe-cafc5b381f4d"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-280f2dbb8708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mimage_noise_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_noise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mimage_restored_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_noise_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mimage_restored_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_restored_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Deep_KSVD.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoft_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoft_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Deep_KSVD.py\u001b[0m in \u001b[0;36msoft_thresh\u001b[0;34m(self, x, l)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msoft_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoft_comp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# List PSNR:\n",
        "file_to_print = open(\"list_test_PSNR.csv\", \"w\")\n",
        "file_to_print.write(str(device) + \"\\n\")\n",
        "file_to_print.flush()\n",
        "\n",
        "with open(\"list_test_PSNR.txt\", \"wb\") as fp:\n",
        "    with torch.no_grad():\n",
        "        list_PSNR = []\n",
        "        list_PSNR_init = []\n",
        "        PSNR = 0\n",
        "        for k, (image_true, image_noise) in enumerate(dataloader_test, 0):\n",
        "\n",
        "            image_true_t = image_true[0, 0, :, :]\n",
        "            image_true_t = image_true_t.to(device)\n",
        "\n",
        "            image_noise_0 = image_noise[0, 0, :, :]\n",
        "            image_noise_0 = image_noise_0.to(device)\n",
        "\n",
        "            image_noise_t = image_noise.to(device)\n",
        "            image_restored_t = model(image_noise_t)\n",
        "            image_restored_t = image_restored_t[0, 0, :, :]\n",
        "\n",
        "            PSNR_init = 10 * torch.log10(\n",
        "                4 / torch.mean((image_true_t - image_noise_0) ** 2)\n",
        "            )\n",
        "            file_to_print.write(\"Init:\" + \" \" + str(PSNR_init) + \"\\n\")\n",
        "            file_to_print.flush()\n",
        "\n",
        "            list_PSNR_init.append(PSNR_init)\n",
        "\n",
        "            PSNR = 10 * torch.log10(\n",
        "                4 / torch.mean((image_true_t - image_restored_t) ** 2)\n",
        "            )\n",
        "            PSNR = PSNR.cpu()\n",
        "            file_to_print.write(\"Test:\" + \" \" + str(PSNR) + \"\\n\")\n",
        "            file_to_print.flush()\n",
        "\n",
        "            list_PSNR.append(PSNR)\n",
        "\n",
        "            imsave(\"im_noisy_\"+str(k)+'.pdf',image_noise_0, cmap=cm.gray)\n",
        "            imsave(\"im_restored_\"+str(k)+'.pdf',image_restored_t, cmap=cm.gray)\n",
        "\n",
        "\n",
        "\n",
        "    mean = np.mean(list_PSNR)\n",
        "    file_to_print.write(\"FINAL\" + \" \" + str(mean) + \"\\n\")\n",
        "    file_to_print.flush()\n",
        "    pickle.dump(list_PSNR, fp)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNoDC9AxMeCj01ngP7mSuu5",
      "include_colab_link": true,
      "name": "DeepKSVD.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
